{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openl3\n",
    "import soundfile as sf\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # A word name of the input audio\n",
    "# word = 'mussa'\n",
    "\n",
    "# # Folder containing multiple audio of the same word\n",
    "# audio_folder = 'input_audios' + '/' + word\n",
    "audio_folder = 'input_audios'\n",
    "\n",
    "# Output path for embeddings json\n",
    "output_file = \"embeddings/embeddings.json\"\n",
    "\n",
    "# # Create a list to store embeddings\n",
    "# all_embeddings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preload model\n",
    "model = openl3.models.load_audio_embedding_model(input_repr=\"mel256\", content_type=\"music\",\n",
    "                                                 embedding_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load audio file\n",
    "\n",
    "def extract_audio(audio_path):\n",
    "    audio = None\n",
    "    sr = None\n",
    "\n",
    "    try:\n",
    "        audio, sr = sf.read(audio_path)\n",
    "        print(sr)\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening the audio file: {e}\")\n",
    "    \n",
    "    return audio, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio(audio, sr):\n",
    "    if audio is not None and sr is not None:\n",
    "        # Extract audio features using OpenL3\n",
    "        embeddings, timestamps = openl3.get_audio_embedding(audio, sr, model)\n",
    "        # print(\"embeddings: \", embeddings)\n",
    "        print(\"timestamps: \", timestamps)\n",
    "        return embeddings\n",
    "    else:\n",
    "        print(\"No generated embeddings for the given audio file\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_avg_embedding(all_embeddings):\n",
    "\n",
    "    # # Find the maximum length of embeddings\n",
    "    # max_length = max(len(entry[\"embedding\"]) for entry in data)\n",
    "\n",
    "    # # Pad or truncate embeddings to have the same length\n",
    "    # for entry in data:\n",
    "    #     while len(entry[\"embedding\"]) < max_length:\n",
    "    #         entry[\"embedding\"].append([0.0, 0.0, 0.0])  # Pad with zeros\n",
    "\n",
    "    # # Convert embeddings to a NumPy array\n",
    "    # all_embeddings = np.array([entry[\"embedding\"] for entry in data])\n",
    "\n",
    "    # Find the maximum length of embeddings\n",
    "    max_length = max(embedding.shape[0] for embedding in all_embeddings)\n",
    "\n",
    "    # Pad or truncate embeddings to have the same length\n",
    "    for i, embedding in enumerate(all_embeddings):\n",
    "        if embedding.shape[0] < max_length:\n",
    "            # Pad with zeros to match the max length\n",
    "            padding_rows = max_length - embedding.shape[0]\n",
    "            zeros_padding = np.zeros((padding_rows, embedding.shape[1]))\n",
    "            all_embeddings[i] = np.vstack((embedding, zeros_padding))\n",
    "        elif embedding.shape[0] > max_length:\n",
    "            # Truncate to match the max length\n",
    "            all_embeddings[i] = embedding[:max_length, :]\n",
    "\n",
    "    # Convert embeddings to a NumPy array\n",
    "    all_embeddings = np.array(all_embeddings)\n",
    "    \n",
    "    # Calculate the mean of embeddings\n",
    "    average_embedding = np.mean(all_embeddings, axis=0)\n",
    "\n",
    "    return average_embedding\n",
    "\n",
    "# Function to Process audio file on all steps at once\n",
    "def process_word(word):\n",
    "    all_embeddings = []\n",
    "    final_folder = audio_folder + '/' + word\n",
    "    # List all audio files in the folder\n",
    "    audio_files = [os.path.join(final_folder, filename) for filename in os.listdir(final_folder) if filename.endswith('-clean.wav')]\n",
    "\n",
    "    print(audio_files)\n",
    "\n",
    "    # Iterate through the audio files and process them\n",
    "    for audio_path in audio_files:\n",
    "        print('Processing file: ', audio_path)\n",
    "        audio, sr = extract_audio(audio_path)\n",
    "        if audio is not None and sr is not None:\n",
    "            embeddings = process_audio(audio, sr)\n",
    "            if embeddings is not None:\n",
    "                # Example: Store embeddings in a list for later use\n",
    "                all_embeddings.append(embeddings)\n",
    "\n",
    "    # print(all_embeddings)\n",
    "\n",
    "    # Calculate the average embedding (if needed)\n",
    "    if all_embeddings:\n",
    "\n",
    "        average_embedding = calculate_avg_embedding(all_embeddings)\n",
    "\n",
    "        existing_data = []\n",
    "\n",
    "        # Load the existing data from the JSON file\n",
    "        with open(output_file, 'r') as json_file:\n",
    "            existing_data = json.load(json_file)\n",
    "\n",
    "        # Check if the word already exists in the data\n",
    "        word_exists = False\n",
    "        for entry in existing_data:\n",
    "            if entry[\"word\"] == word:\n",
    "                # Get current time in milliseconds (since epoch)\n",
    "                current_time_ms = str(int(time.time() * 1000))\n",
    "                entry[\"embeddings\"][current_time_ms] = average_embedding.tolist()\n",
    "                word_exists = True\n",
    "                break\n",
    "        \n",
    "        # If the word doesn't exist, add a new entry\n",
    "        if not word_exists:\n",
    "            # Get current time in milliseconds (since epoch)\n",
    "            current_time_ms = str(int(time.time() * 1000))\n",
    "            new_entry = {\n",
    "                \"word\": word,\n",
    "                \"embeddings\": {\n",
    "                    current_time_ms: average_embedding.tolist()\n",
    "                }\n",
    "            }\n",
    "            existing_data.append(new_entry)\n",
    "        \n",
    "        # # Store the average embedding in a JSON file\n",
    "        # new_entry = {\n",
    "        #     'word': word,\n",
    "        #     'embedding': average_embedding.tolist()\n",
    "        # }\n",
    "\n",
    "        # # Append the new entry to the existing data\n",
    "        # existing_data.append(new_entry)\n",
    "\n",
    "        # Serialize the updated data to JSON and save it back to the file\n",
    "        with open(output_file, 'w') as json_file:\n",
    "            json.dump(existing_data, json_file, indent=2)\n",
    "\n",
    "        print(f'Done creating embeddings for word: {word}')\n",
    "\n",
    "    else: \n",
    "        print(f\"No embeddings generated for the word {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['input_audios/sifuri\\\\1695602217446-clean.wav', 'input_audios/sifuri\\\\1695602271368-clean.wav']\n",
      "Processing file:  input_audios/sifuri\\1695602217446-clean.wav\n",
      "16000\n",
      "1/1 [==============================] - 9s 9s/step\n",
      "timestamps:  [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.  1.1 1.2]\n",
      "Processing file:  input_audios/sifuri\\1695602271368-clean.wav\n",
      "16000\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "timestamps:  [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n",
      "Done creating embeddings for word: sifuri\n"
     ]
    }
   ],
   "source": [
    "# process all available words in the input_audios folder\n",
    "\n",
    "# process_word('mussa')\n",
    "# process_word('moja')\n",
    "# process_word('mbili')\n",
    "# process_word('tatu')\n",
    "# process_word('nne')\n",
    "# process_word('tano')\n",
    "# process_word('sita')\n",
    "# process_word('saba')\n",
    "# process_word('nane')\n",
    "# process_word('tisa')\n",
    "# process_word('kumi')\n",
    "process_word('sifuri')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
