{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "ValidatedGraphConfig Initialization failed.\nNo registered object with name: mediapipe::tasks::text::text_embedder::TextEmbedderGraph; Unable to find Calculator \"mediapipe.tasks.text.text_embedder.TextEmbedderGraph\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\Projects\\ml-enthusiast\\nlp\\text_embedder.ipynb Cell 1\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/ml-enthusiast/nlp/text_embedder.ipynb#W0sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Create the final set of options for the Embedder\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/ml-enthusiast/nlp/text_embedder.ipynb#W0sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m options \u001b[39m=\u001b[39m text\u001b[39m.\u001b[39mTextEmbedderOptions(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/ml-enthusiast/nlp/text_embedder.ipynb#W0sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     base_options\u001b[39m=\u001b[39mbase_options,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/ml-enthusiast/nlp/text_embedder.ipynb#W0sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     l2_normalize\u001b[39m=\u001b[39ml2_normalize,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/ml-enthusiast/nlp/text_embedder.ipynb#W0sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     quantize\u001b[39m=\u001b[39mquantize\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/ml-enthusiast/nlp/text_embedder.ipynb#W0sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Projects/ml-enthusiast/nlp/text_embedder.ipynb#W0sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mwith\u001b[39;00m text\u001b[39m.\u001b[39;49mTextEmbedder\u001b[39m.\u001b[39;49mcreate_from_options(options) \u001b[39mas\u001b[39;00m embedder:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/ml-enthusiast/nlp/text_embedder.ipynb#W0sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39m# Retrieve the first and second sets of text that will be compared\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/ml-enthusiast/nlp/text_embedder.ipynb#W0sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     first_text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mI\u001b[39m\u001b[39m'\u001b[39m\u001b[39mm feeling so good\u001b[39m\u001b[39m\"\u001b[39m  \u001b[39m# @param {type:\"string\"}\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/ml-enthusiast/nlp/text_embedder.ipynb#W0sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     second_text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mI\u001b[39m\u001b[39m'\u001b[39m\u001b[39mm okay I guess\u001b[39m\u001b[39m\"\u001b[39m  \u001b[39m# @param {type:\"string\"}\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\mediapipe\\tasks\\python\\text\\text_embedder.py:140\u001b[0m, in \u001b[0;36mTextEmbedder.create_from_options\u001b[1;34m(cls, options)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Creates the `TextEmbedder` object from text embedder options.\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \n\u001b[0;32m    122\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[39m  RuntimeError: If other types of error occurred.\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    133\u001b[0m task_info \u001b[39m=\u001b[39m _TaskInfo(\n\u001b[0;32m    134\u001b[0m     task_graph\u001b[39m=\u001b[39m_TASK_GRAPH_NAME,\n\u001b[0;32m    135\u001b[0m     input_streams\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([_TEXT_TAG, _TEXT_IN_STREAM_NAME])],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m     ],\n\u001b[0;32m    139\u001b[0m     task_options\u001b[39m=\u001b[39moptions)\n\u001b[1;32m--> 140\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(task_info\u001b[39m.\u001b[39;49mgenerate_graph_config())\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\mediapipe\\tasks\\python\\text\\core\\base_text_task_api.py:34\u001b[0m, in \u001b[0;36mBaseTextTaskApi.__init__\u001b[1;34m(self, graph_config)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[0;32m     28\u001b[0m              graph_config: calculator_pb2\u001b[39m.\u001b[39mCalculatorGraphConfig) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     29\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Initializes the `BaseVisionTaskApi` object.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \n\u001b[0;32m     31\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[39m    graph_config: The mediapipe text task graph config proto.\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_runner \u001b[39m=\u001b[39m _TaskRunner\u001b[39m.\u001b[39;49mcreate(graph_config)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: ValidatedGraphConfig Initialization failed.\nNo registered object with name: mediapipe::tasks::text::text_embedder::TextEmbedderGraph; Unable to find Calculator \"mediapipe.tasks.text.text_embedder.TextEmbedderGraph\""
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import text\n",
    "\n",
    "mp.__version__\n",
    "\n",
    "model_path = 'models/universal_sentence_encoder.tflite'\n",
    "\n",
    "# Create your base options with the model\n",
    "base_options = python.BaseOptions(model_asset_path=model_path)\n",
    "\n",
    "# Set your values for using normalization and quantization\n",
    "l2_normalize = True  # @param {type:\"boolean\"}\n",
    "quantize = False  # @param {type:\"boolean\"}\n",
    "\n",
    "# Create the final set of options for the Embedder\n",
    "options = text.TextEmbedderOptions(\n",
    "    base_options=base_options,\n",
    "    l2_normalize=l2_normalize,\n",
    "    quantize=quantize\n",
    ")\n",
    "\n",
    "with text.TextEmbedder.create_from_options(options) as embedder:\n",
    "    # Retrieve the first and second sets of text that will be compared\n",
    "    first_text = \"I'm feeling so good\"  # @param {type:\"string\"}\n",
    "    second_text = \"I'm okay I guess\"  # @param {type:\"string\"}\n",
    "\n",
    "    # Convert both sets of text to embeddings\n",
    "    first_embedding_result = embedder.embed(first_text)\n",
    "    second_embedding_result = embedder.embed(second_text)\n",
    "\n",
    "    # Calculate and print similarity\n",
    "    similarity = text.TextEmbedder.cosine_similarity(\n",
    "        first_embedding_result.embeddings[0],\n",
    "        second_embedding_result.embeddings[0])\n",
    "    print(similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'to_pb2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\Projects\\ml-enthusiast\\nlp\\text_embedder.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/ml-enthusiast/nlp/text_embedder.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Create the final set of options for the Embedder\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/ml-enthusiast/nlp/text_embedder.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m options \u001b[39m=\u001b[39m text\u001b[39m.\u001b[39mTextEmbedderOptions(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/ml-enthusiast/nlp/text_embedder.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     base_options\u001b[39m=\u001b[39mbase_options, \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/ml-enthusiast/nlp/text_embedder.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     l2_normalize\u001b[39m=\u001b[39ml2_normalize, \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/ml-enthusiast/nlp/text_embedder.ipynb#W1sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     quantize\u001b[39m=\u001b[39mquantize\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/ml-enthusiast/nlp/text_embedder.ipynb#W1sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Projects/ml-enthusiast/nlp/text_embedder.ipynb#W1sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mwith\u001b[39;00m text\u001b[39m.\u001b[39;49mTextEmbedder\u001b[39m.\u001b[39;49mcreate_from_options(options) \u001b[39mas\u001b[39;00m embedder:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/ml-enthusiast/nlp/text_embedder.ipynb#W1sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m   \u001b[39m# Retrieve the first and second sets of text that will be compared\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/ml-enthusiast/nlp/text_embedder.ipynb#W1sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m   first_text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mI\u001b[39m\u001b[39m'\u001b[39m\u001b[39mm feeling so good\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m#@param {type:\"string\"}\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/ml-enthusiast/nlp/text_embedder.ipynb#W1sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m   second_text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mI\u001b[39m\u001b[39m'\u001b[39m\u001b[39mm okay I guess\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m#@param {type:\"string\"}\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Mussa\\.conda\\envs\\ml_env_38\\lib\\site-packages\\mediapipe\\tasks\\python\\text\\text_embedder.py:140\u001b[0m, in \u001b[0;36mTextEmbedder.create_from_options\u001b[1;34m(cls, options)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Creates the `TextEmbedder` object from text embedder options.\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \n\u001b[0;32m    122\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[39m  RuntimeError: If other types of error occurred.\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    133\u001b[0m task_info \u001b[39m=\u001b[39m _TaskInfo(\n\u001b[0;32m    134\u001b[0m     task_graph\u001b[39m=\u001b[39m_TASK_GRAPH_NAME,\n\u001b[0;32m    135\u001b[0m     input_streams\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([_TEXT_TAG, _TEXT_IN_STREAM_NAME])],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m     ],\n\u001b[0;32m    139\u001b[0m     task_options\u001b[39m=\u001b[39moptions)\n\u001b[1;32m--> 140\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(task_info\u001b[39m.\u001b[39;49mgenerate_graph_config())\n",
      "File \u001b[1;32mc:\\Users\\Mussa\\.conda\\envs\\ml_env_38\\lib\\site-packages\\mediapipe\\tasks\\python\\core\\task_info.py:84\u001b[0m, in \u001b[0;36mTaskInfo.generate_graph_config\u001b[1;34m(self, enable_flow_limiting)\u001b[0m\n\u001b[0;32m     80\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     81\u001b[0m       \u001b[39m'\u001b[39m\u001b[39m`task_options` doesn`t provide `to_pb2()` method to convert itself to be a protobuf object.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     82\u001b[0m   )\n\u001b[0;32m     83\u001b[0m task_subgraph_options \u001b[39m=\u001b[39m calculator_options_pb2\u001b[39m.\u001b[39mCalculatorOptions()\n\u001b[1;32m---> 84\u001b[0m task_options_proto \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtask_options\u001b[39m.\u001b[39;49mto_pb2()\n\u001b[0;32m     85\u001b[0m task_subgraph_options\u001b[39m.\u001b[39mExtensions[task_options_proto\u001b[39m.\u001b[39mext]\u001b[39m.\u001b[39mCopyFrom(\n\u001b[0;32m     86\u001b[0m     task_options_proto)\n\u001b[0;32m     87\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m enable_flow_limiting:\n",
      "File \u001b[1;32mc:\\Users\\Mussa\\.conda\\envs\\ml_env_38\\lib\\site-packages\\mediapipe\\tasks\\python\\text\\text_embedder.py:66\u001b[0m, in \u001b[0;36mTextEmbedderOptions.to_pb2\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39m@doc_controls\u001b[39m\u001b[39m.\u001b[39mdo_not_generate_docs\n\u001b[0;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_pb2\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m _TextEmbedderGraphOptionsProto:\n\u001b[0;32m     65\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Generates an TextEmbedderOptions protobuf object.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m   base_options_proto \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbase_options\u001b[39m.\u001b[39;49mto_pb2()\n\u001b[0;32m     67\u001b[0m   embedder_options_proto \u001b[39m=\u001b[39m _EmbedderOptionsProto(\n\u001b[0;32m     68\u001b[0m       l2_normalize\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39ml2_normalize, quantize\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquantize)\n\u001b[0;32m     70\u001b[0m   \u001b[39mreturn\u001b[39;00m _TextEmbedderGraphOptionsProto(\n\u001b[0;32m     71\u001b[0m       base_options\u001b[39m=\u001b[39mbase_options_proto,\n\u001b[0;32m     72\u001b[0m       embedder_options\u001b[39m=\u001b[39membedder_options_proto)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'to_pb2'"
     ]
    }
   ],
   "source": [
    "model_path = 'models/universal_sentence_encoder.tflite'\n",
    "\n",
    "# Create your base options with the model\n",
    "base_options=python.BaseOptions(model_asset_path=model_path),\n",
    "\n",
    "# Set your values for using normalization and quantization\n",
    "l2_normalize = True #@param {type:\"boolean\"}\n",
    "quantize = False #@param {type:\"boolean\"}\n",
    "\n",
    "\n",
    "# Create the final set of options for the Embedder\n",
    "options = text.TextEmbedderOptions(\n",
    "    base_options=base_options, \n",
    "    l2_normalize=l2_normalize, \n",
    "    quantize=quantize\n",
    ")\n",
    "\n",
    "with text.TextEmbedder.create_from_options(options) as embedder:\n",
    "  # Retrieve the first and second sets of text that will be compared\n",
    "  first_text = \"I'm feeling so good\" #@param {type:\"string\"}\n",
    "  second_text = \"I'm okay I guess\" #@param {type:\"string\"}\n",
    "\n",
    "  # Convert both sets of text to embeddings\n",
    "  first_embedding_result = embedder.embed(first_text)\n",
    "  second_embedding_result = embedder.embed(second_text)\n",
    "\n",
    "  # Calculate and print similarity\n",
    "  similarity = text.TextEmbedder.cosine_similarity(\n",
    "      first_embedding_result.embeddings[0],\n",
    "      second_embedding_result.embeddings[0])\n",
    "  print(similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "\n",
    "input_text = \"The input text to be embedded.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform text embedding on the provided input text.\n",
    "\n",
    "embedding_result = text_embedder.embed(input_text)\n",
    "\n",
    "embedding_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute cosine similarity.\n",
    "# similarity = TextEmbedder.cosine_similarity(\n",
    "#   embedding_result.embeddings[0],\n",
    "#   other_embedding_result.embeddings[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
