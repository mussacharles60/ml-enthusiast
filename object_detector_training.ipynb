{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages.\n",
    "\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mussa\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflowjs\\write_weights.py:28: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  np.uint8, np.uint16, np.bool, np.object]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'bool'.\n`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\Projects\\ml-enthusiast\\object_detector_training.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Projects/ml-enthusiast/object_detector_training.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtflite_model_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m ExportFormat, QuantizationConfig\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/ml-enthusiast/object_detector_training.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtflite_model_maker\u001b[39;00m \u001b[39mimport\u001b[39;00m model_spec\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/ml-enthusiast/object_detector_training.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtflite_model_maker\u001b[39;00m \u001b[39mimport\u001b[39;00m object_detector\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tflite_model_maker\\__init__.py:44\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright 2021 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39m# pylint: disable=g-bad-import-order,redefined-builtin\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"Public APIs for TFLite Model Maker, a transfer learning library to train custom TFLite models.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[39mYou can install the package with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[39mhttps://www.tensorflow.org/lite/guide/model_maker.\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtflite_model_maker\u001b[39;00m \u001b[39mimport\u001b[39;00m audio_classifier\n\u001b[0;32m     45\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtflite_model_maker\u001b[39;00m \u001b[39mimport\u001b[39;00m config\n\u001b[0;32m     46\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtflite_model_maker\u001b[39;00m \u001b[39mimport\u001b[39;00m image_classifier\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tflite_model_maker\\audio_classifier\\__init__.py:24\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright 2021 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39m# pylint: disable=g-bad-import-order,redefined-builtin\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"APIs to train an audio classification model.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[39mTutorial:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mhttps://github.com/tensorflow/examples/blob/master/tensorflow_examples/lite/model_maker/demo/audio_classification_demo.py\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_util\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maudio_dataloader\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoader\n\u001b[0;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maudio_classifier\u001b[39;00m \u001b[39mimport\u001b[39;00m AudioClassifier\n\u001b[0;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maudio_classifier\u001b[39;00m \u001b[39mimport\u001b[39;00m create\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow_examples\\lite\\model_maker\\core\\data_util\\audio_dataloader.py:27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi_util\u001b[39;00m \u001b[39mimport\u001b[39;00m mm_export\n\u001b[0;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_util\u001b[39;00m \u001b[39mimport\u001b[39;00m dataloader\n\u001b[1;32m---> 27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_spec\u001b[39;00m \u001b[39mimport\u001b[39;00m audio_spec\n\u001b[0;32m     29\u001b[0m error_import_librosa \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow_examples\\lite\\model_maker\\core\\task\\model_spec\\__init__.py:20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39minspect\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m mm_export\n\u001b[1;32m---> 20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_spec\u001b[39;00m \u001b[39mimport\u001b[39;00m audio_spec\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_spec\u001b[39;00m \u001b[39mimport\u001b[39;00m image_spec\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_spec\u001b[39;00m \u001b[39mimport\u001b[39;00m object_detector_spec\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow_examples\\lite\\model_maker\\core\\task\\model_spec\\audio_spec.py:29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi_util\u001b[39;00m \u001b[39mimport\u001b[39;00m mm_export\n\u001b[1;32m---> 29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m \u001b[39mimport\u001b[39;00m model_util\n\u001b[0;32m     30\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow_hub\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mhub\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow_examples\\lite\\model_maker\\core\\task\\model_util.py:28\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m compat\n\u001b[1;32m---> 28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m \u001b[39mimport\u001b[39;00m converter \u001b[39mas\u001b[39;00m tfjs_converter\n\u001b[0;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtflite_support\u001b[39;00m \u001b[39mimport\u001b[39;00m metadata \u001b[39mas\u001b[39;00m _metadata\n\u001b[0;32m     31\u001b[0m DEFAULT_SCALE, DEFAULT_ZERO_POINT \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflowjs\\__init__.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m print_function\n\u001b[0;32m     20\u001b[0m \u001b[39m# pylint: disable=unused-imports\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m \u001b[39mimport\u001b[39;00m converters\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m \u001b[39mimport\u001b[39;00m quantization\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m \u001b[39mimport\u001b[39;00m version\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflowjs\\converters\\__init__.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m print_function\n\u001b[0;32m     20\u001b[0m \u001b[39m# pylint: disable=unused-imports,line-too-long\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverter\u001b[39;00m \u001b[39mimport\u001b[39;00m convert\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras_h5_conversion\u001b[39;00m \u001b[39mimport\u001b[39;00m save_keras_model\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras_tfjs_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m deserialize_keras_model\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflowjs\\converters\\converter.py:35\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m \u001b[39mimport\u001b[39;00m version\n\u001b[0;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m \u001b[39mimport\u001b[39;00m common\n\u001b[1;32m---> 35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m \u001b[39mimport\u001b[39;00m keras_h5_conversion \u001b[39mas\u001b[39;00m conversion\n\u001b[0;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m \u001b[39mimport\u001b[39;00m keras_tfjs_loader\n\u001b[0;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m \u001b[39mimport\u001b[39;00m tf_saved_model_conversion_v2\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflowjs\\converters\\keras_h5_conversion.py:33\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mh5py\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m \u001b[39mimport\u001b[39;00m write_weights  \u001b[39m# pylint: disable=import-error\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m \u001b[39mimport\u001b[39;00m common\n\u001b[0;32m     37\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnormalize_weight_name\u001b[39m(weight_name):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflowjs\\write_weights.py:28\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m \u001b[39mimport\u001b[39;00m quantization\n\u001b[0;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m \u001b[39mimport\u001b[39;00m read_weights\n\u001b[0;32m     27\u001b[0m _OUTPUT_DTYPES \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mfloat16, np\u001b[39m.\u001b[39mfloat32, np\u001b[39m.\u001b[39mint32, np\u001b[39m.\u001b[39mcomplex64,\n\u001b[1;32m---> 28\u001b[0m                   np\u001b[39m.\u001b[39muint8, np\u001b[39m.\u001b[39muint16, np\u001b[39m.\u001b[39;49mbool, np\u001b[39m.\u001b[39mobject]\n\u001b[0;32m     29\u001b[0m _AUTO_DTYPE_CONVERSION \u001b[39m=\u001b[39m {\n\u001b[0;32m     30\u001b[0m     np\u001b[39m.\u001b[39mdtype(np\u001b[39m.\u001b[39mfloat16): np\u001b[39m.\u001b[39mfloat32,\n\u001b[0;32m     31\u001b[0m     np\u001b[39m.\u001b[39mdtype(np\u001b[39m.\u001b[39mfloat64): np\u001b[39m.\u001b[39mfloat32,\n\u001b[0;32m     32\u001b[0m     np\u001b[39m.\u001b[39mdtype(np\u001b[39m.\u001b[39mint64): np\u001b[39m.\u001b[39mint32,\n\u001b[0;32m     33\u001b[0m     np\u001b[39m.\u001b[39mdtype(np\u001b[39m.\u001b[39mcomplex128): np\u001b[39m.\u001b[39mcomplex64}\n\u001b[0;32m     35\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrite_weights\u001b[39m(\n\u001b[0;32m     36\u001b[0m     weight_groups, write_dir, shard_size_bytes\u001b[39m=\u001b[39m\u001b[39m1024\u001b[39m \u001b[39m*\u001b[39m \u001b[39m1024\u001b[39m \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m,\n\u001b[0;32m     37\u001b[0m     write_manifest\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, quantization_dtype_map\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py:305\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    300\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    301\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIn the future `np.\u001b[39m\u001b[39m{\u001b[39;00mattr\u001b[39m}\u001b[39;00m\u001b[39m` will be defined as the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    302\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcorresponding NumPy scalar.\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFutureWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m    304\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39min\u001b[39;00m __former_attrs__:\n\u001b[1;32m--> 305\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[0;32m    307\u001b[0m \u001b[39m# Importing Tester requires importing all of UnitTest which is not a\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[39m# cheap import Since it is mainly used in test suits, we lazy import it\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[39m# here to save on the order of 10 ms of import time for most users\u001b[39;00m\n\u001b[0;32m    310\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m    311\u001b[0m \u001b[39m# The previous way Tester was imported also had a side effect of adding\u001b[39;00m\n\u001b[0;32m    312\u001b[0m \u001b[39m# the full `numpy.testing` namespace\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtesting\u001b[39m\u001b[39m'\u001b[39m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'bool'.\n`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "from tflite_model_maker.config import ExportFormat, QuantizationConfig\n",
    "from tflite_model_maker import model_spec\n",
    "from tflite_model_maker import object_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tflite_support import metadata\n",
    "\n",
    "import tensorflow as tf\n",
    "assert tf.__version__.startswith('2')\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "from absl import logging\n",
    "logging.set_verbosity(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'object_detector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Projects\\ml-enthusiast\\object_detector_training.ipynb Cell 6\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/ml-enthusiast/object_detector_training.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/ml-enthusiast/object_detector_training.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m   Train the object detection model\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/ml-enthusiast/object_detector_training.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m   Step 1: Load the dataset\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/ml-enthusiast/object_detector_training.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m   Images in train_data is used to train the custom object detection model.\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/ml-enthusiast/object_detector_training.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m   Images in val_data is used to check if the model can generalize well to new images that it hasn't seen before.\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/ml-enthusiast/object_detector_training.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Projects/ml-enthusiast/object_detector_training.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m train_data \u001b[39m=\u001b[39m object_detector\u001b[39m.\u001b[39mDataLoader\u001b[39m.\u001b[39mfrom_pascal_voc(\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/ml-enthusiast/object_detector_training.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mdatasets/android_figurine/train\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/ml-enthusiast/object_detector_training.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mdatasets/android_figurine/train\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/ml-enthusiast/object_detector_training.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     [\u001b[39m'\u001b[39m\u001b[39mandroid\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpig_android\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/ml-enthusiast/object_detector_training.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/ml-enthusiast/object_detector_training.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m val_data \u001b[39m=\u001b[39m object_detector\u001b[39m.\u001b[39mDataLoader\u001b[39m.\u001b[39mfrom_pascal_voc(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/ml-enthusiast/object_detector_training.ipynb#W1sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mdatasets/android_figurine/validate\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/ml-enthusiast/object_detector_training.ipynb#W1sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mdatasets/android_figurine/validate\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/ml-enthusiast/object_detector_training.ipynb#W1sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     [\u001b[39m'\u001b[39m\u001b[39mandroid\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpig_android\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/ml-enthusiast/object_detector_training.ipynb#W1sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'object_detector' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "   Train the object detection model\n",
    "   Step 1: Load the dataset\n",
    "   Images in train_data is used to train the custom object detection model.\n",
    "   Images in val_data is used to check if the model can generalize well to new images that it hasn't seen before.\n",
    "\"\"\"\n",
    "\n",
    "train_data = object_detector.DataLoader.from_pascal_voc(\n",
    "    'datasets/android_figurine/train',\n",
    "    'datasets/android_figurine/train',\n",
    "    ['android', 'pig_android']\n",
    ")\n",
    "\n",
    "val_data = object_detector.DataLoader.from_pascal_voc(\n",
    "    'datasets/android_figurine/validate',\n",
    "    'datasets/android_figurine/validate',\n",
    "    ['android', 'pig_android']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "   Step 2: Select a model architecture\n",
    "   EfficientDet-Lite[0-4] are a family of mobile/IoT-friendly object detection models derived from the EfficientDet architecture.\n",
    "\"\"\"\n",
    "\n",
    "spec = model_spec.get('efficientdet_lite0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "   Step 3: Train the TensorFlow model with the training data.\n",
    "   Set epochs = 20, which means it will go through the training dataset 20 times. You can look at the validation accuracy during training and stop when you see validation loss (val_loss) stop decreasing to avoid overfitting.\n",
    "   Set batch_size = 4 here so you will see that it takes 15 steps to go through the 62 images in the training dataset.\n",
    "   Set train_whole_model=True to fine-tune the whole model instead of just training the head layer to improve accuracy. The trade-off is that it may take longer to train the model.\n",
    "\"\"\"\n",
    "\n",
    "model = object_detector.create(\n",
    "    train_data, \n",
    "    model_spec=spec, \n",
    "    batch_size=4, \n",
    "    train_whole_model=True, \n",
    "    epochs=20, \n",
    "    validation_data=val_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "   Step 4. Evaluate the model with the validation data.\n",
    "   After training the object detection model using the images in the training dataset, use the 10 images in the validation dataset to evaluate how the model performs against new data it has never seen before.\n",
    "\n",
    "   As the default batch size is 64, it will take 1 step to go through the 10 images in the validation dataset.\n",
    "\n",
    "   The evaluation metrics are same as COCO.\n",
    "\"\"\"\n",
    "\n",
    "model.evaluate(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "   Step 5: Export as a TensorFlow Lite model.\n",
    "   Export the trained object detection model to the TensorFlow Lite format by specifying which folder you want to export the quantized model to. \n",
    "   The default post-training quantization technique is full integer quantization. \n",
    "   This allows the TensorFlow Lite model to be smaller, run faster on Raspberry Pi CPU and also compatible with the Google Coral EdgeTPU.\n",
    "\"\"\"\n",
    "\n",
    "model.export(export_dir='./models/', tflite_filename='android.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "   Step 6: Evaluate the TensorFlow Lite model.\n",
    "   Several factors can affect the model accuracy when exporting to TFLite:\n",
    "\n",
    "   Quantization helps shrinking the model size by 4 times at the expense of some accuracy drop.\n",
    "   The original TensorFlow model uses per-class non-max supression (NMS) for post-processing, while the TFLite model uses global NMS that's much faster but less accurate. \n",
    "   Keras outputs maximum 100 detections while tflite outputs maximum 25 detections.\n",
    "   Therefore you'll have to evaluate the exported TFLite model and compare its accuracy with the original TensorFlow model.\n",
    "\"\"\"\n",
    "\n",
    "model.evaluate_tflite('android.tflite', val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env_39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
