{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Mussa\\AppData\\Local\\llama_index...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "ename": "RetryError",
     "evalue": "RetryError[<Future at 0x21e96350fd0 state=finished raised RateLimitError>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Mussa\\.conda\\envs\\ml_env_38\\lib\\site-packages\\tenacity\\__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 382\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    383\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Projects\\llama_index\\llama_index\\embeddings\\openai.py:169\u001b[0m, in \u001b[0;36mget_embeddings\u001b[1;34m(list_of_text, engine, **kwargs)\u001b[0m\n\u001b[0;32m    167\u001b[0m list_of_text \u001b[39m=\u001b[39m [text\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m list_of_text]\n\u001b[1;32m--> 169\u001b[0m data \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mEmbedding\u001b[39m.\u001b[39;49mcreate(\u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mlist_of_text, model\u001b[39m=\u001b[39;49mengine, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\u001b[39m.\u001b[39mdata\n\u001b[0;32m    170\u001b[0m \u001b[39mreturn\u001b[39;00m [d[\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m data]\n",
      "File \u001b[1;32mc:\\Users\\Mussa\\.conda\\envs\\ml_env_38\\lib\\site-packages\\openai\\api_resources\\embedding.py:33\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 33\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     35\u001b[0m     \u001b[39m# If a user specifies base64, we'll just return the encoded string.\u001b[39;00m\n\u001b[0;32m     36\u001b[0m     \u001b[39m# This is only for the default case.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Mussa\\.conda\\envs\\ml_env_38\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:155\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    140\u001b[0m (\n\u001b[0;32m    141\u001b[0m     deployment_id,\n\u001b[0;32m    142\u001b[0m     engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    152\u001b[0m     api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    153\u001b[0m )\n\u001b[1;32m--> 155\u001b[0m response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    156\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    157\u001b[0m     url,\n\u001b[0;32m    158\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    159\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    160\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    161\u001b[0m     request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    162\u001b[0m     request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    163\u001b[0m )\n\u001b[0;32m    165\u001b[0m \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    166\u001b[0m     \u001b[39m# must be an iterator\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Mussa\\.conda\\envs\\ml_env_38\\lib\\site-packages\\openai\\api_requestor.py:299\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    289\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    290\u001b[0m     method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    291\u001b[0m     url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    297\u001b[0m     request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    298\u001b[0m )\n\u001b[1;32m--> 299\u001b[0m resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    300\u001b[0m \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\Mussa\\.conda\\envs\\ml_env_38\\lib\\site-packages\\openai\\api_requestor.py:710\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    709\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 710\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    711\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    712\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    713\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    714\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    715\u001b[0m         ),\n\u001b[0;32m    716\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    717\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Mussa\\.conda\\envs\\ml_env_38\\lib\\site-packages\\openai\\api_requestor.py:775\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    774\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 775\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    776\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    777\u001b[0m     )\n\u001b[0;32m    778\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRetryError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Projects\\ml-enthusiast\\llama\\new_test.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/ml-enthusiast/llama/new_test.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m documents \u001b[39m=\u001b[39m SimpleDirectoryReader(\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mload_data()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Projects/ml-enthusiast/llama/new_test.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m index \u001b[39m=\u001b[39m VectorStoreIndex\u001b[39m.\u001b[39;49mfrom_documents(documents)\n",
      "File \u001b[1;32mD:\\Projects\\llama_index\\llama_index\\indices\\base.py:102\u001b[0m, in \u001b[0;36mBaseIndex.from_documents\u001b[1;34m(cls, documents, storage_context, service_context, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m     97\u001b[0m     docstore\u001b[39m.\u001b[39mset_document_hash(doc\u001b[39m.\u001b[39mget_doc_id(), doc\u001b[39m.\u001b[39mhash)\n\u001b[0;32m     98\u001b[0m nodes \u001b[39m=\u001b[39m service_context\u001b[39m.\u001b[39mnode_parser\u001b[39m.\u001b[39mget_nodes_from_documents(\n\u001b[0;32m     99\u001b[0m     documents, show_progress\u001b[39m=\u001b[39mshow_progress\n\u001b[0;32m    100\u001b[0m )\n\u001b[1;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(\n\u001b[0;32m    103\u001b[0m     nodes\u001b[39m=\u001b[39;49mnodes,\n\u001b[0;32m    104\u001b[0m     storage_context\u001b[39m=\u001b[39;49mstorage_context,\n\u001b[0;32m    105\u001b[0m     service_context\u001b[39m=\u001b[39;49mservice_context,\n\u001b[0;32m    106\u001b[0m     show_progress\u001b[39m=\u001b[39;49mshow_progress,\n\u001b[0;32m    107\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    108\u001b[0m )\n",
      "File \u001b[1;32mD:\\Projects\\llama_index\\llama_index\\indices\\vector_store\\base.py:49\u001b[0m, in \u001b[0;36mVectorStoreIndex.__init__\u001b[1;34m(self, nodes, index_struct, service_context, storage_context, use_async, store_nodes_override, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_async \u001b[39m=\u001b[39m use_async\n\u001b[0;32m     48\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_store_nodes_override \u001b[39m=\u001b[39m store_nodes_override\n\u001b[1;32m---> 49\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[0;32m     50\u001b[0m     nodes\u001b[39m=\u001b[39;49mnodes,\n\u001b[0;32m     51\u001b[0m     index_struct\u001b[39m=\u001b[39;49mindex_struct,\n\u001b[0;32m     52\u001b[0m     service_context\u001b[39m=\u001b[39;49mservice_context,\n\u001b[0;32m     53\u001b[0m     storage_context\u001b[39m=\u001b[39;49mstorage_context,\n\u001b[0;32m     54\u001b[0m     show_progress\u001b[39m=\u001b[39;49mshow_progress,\n\u001b[0;32m     55\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m     56\u001b[0m )\n",
      "File \u001b[1;32mD:\\Projects\\llama_index\\llama_index\\indices\\base.py:71\u001b[0m, in \u001b[0;36mBaseIndex.__init__\u001b[1;34m(self, nodes, index_struct, storage_context, service_context, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[39mif\u001b[39;00m index_struct \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m     \u001b[39massert\u001b[39;00m nodes \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m     index_struct \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuild_index_from_nodes(nodes)\n\u001b[0;32m     72\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_struct \u001b[39m=\u001b[39m index_struct\n\u001b[0;32m     73\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_storage_context\u001b[39m.\u001b[39mindex_store\u001b[39m.\u001b[39madd_index_struct(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_struct)\n",
      "File \u001b[1;32mD:\\Projects\\llama_index\\llama_index\\indices\\vector_store\\base.py:238\u001b[0m, in \u001b[0;36mVectorStoreIndex.build_index_from_nodes\u001b[1;34m(self, nodes)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild_index_from_nodes\u001b[39m(\u001b[39mself\u001b[39m, nodes: Sequence[BaseNode]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m IndexDict:\n\u001b[0;32m    232\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build the index from nodes.\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \n\u001b[0;32m    234\u001b[0m \u001b[39m    NOTE: Overrides BaseIndex.build_index_from_nodes.\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[39m        VectorStoreIndex only stores nodes in document store\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[39m        if vector store does not store text\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 238\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_index_from_nodes(nodes)\n",
      "File \u001b[1;32mD:\\Projects\\llama_index\\llama_index\\indices\\vector_store\\base.py:226\u001b[0m, in \u001b[0;36mVectorStoreIndex._build_index_from_nodes\u001b[1;34m(self, nodes)\u001b[0m\n\u001b[0;32m    224\u001b[0m     run_async_tasks(tasks)\n\u001b[0;32m    225\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 226\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_add_nodes_to_index(\n\u001b[0;32m    227\u001b[0m         index_struct, nodes, show_progress\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_show_progress\n\u001b[0;32m    228\u001b[0m     )\n\u001b[0;32m    229\u001b[0m \u001b[39mreturn\u001b[39;00m index_struct\n",
      "File \u001b[1;32mD:\\Projects\\llama_index\\llama_index\\indices\\vector_store\\base.py:186\u001b[0m, in \u001b[0;36mVectorStoreIndex._add_nodes_to_index\u001b[1;34m(self, index_struct, nodes, show_progress)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m nodes:\n\u001b[0;32m    184\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 186\u001b[0m nodes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_node_with_embedding(nodes, show_progress)\n\u001b[0;32m    187\u001b[0m new_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vector_store\u001b[39m.\u001b[39madd(nodes)\n\u001b[0;32m    189\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vector_store\u001b[39m.\u001b[39mstores_text \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_store_nodes_override:\n\u001b[0;32m    190\u001b[0m     \u001b[39m# NOTE: if the vector store doesn't store text,\u001b[39;00m\n\u001b[0;32m    191\u001b[0m     \u001b[39m# we need to add the nodes to the index struct and document store\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Projects\\llama_index\\llama_index\\indices\\vector_store\\base.py:100\u001b[0m, in \u001b[0;36mVectorStoreIndex._get_node_with_embedding\u001b[1;34m(self, nodes, show_progress)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_node_with_embedding\u001b[39m(\n\u001b[0;32m     90\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     91\u001b[0m     nodes: Sequence[BaseNode],\n\u001b[0;32m     92\u001b[0m     show_progress: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m     93\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[BaseNode]:\n\u001b[0;32m     94\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get tuples of id, node, and embedding.\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \n\u001b[0;32m     96\u001b[0m \u001b[39m    Allows us to store these nodes in a vector store.\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[39m    Embeddings are called in batches.\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \n\u001b[0;32m     99\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m     id_to_embed_map \u001b[39m=\u001b[39m embed_nodes(\n\u001b[0;32m    101\u001b[0m         nodes, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_service_context\u001b[39m.\u001b[39;49membed_model, show_progress\u001b[39m=\u001b[39;49mshow_progress\n\u001b[0;32m    102\u001b[0m     )\n\u001b[0;32m    104\u001b[0m     results \u001b[39m=\u001b[39m []\n\u001b[0;32m    105\u001b[0m     \u001b[39mfor\u001b[39;00m node \u001b[39min\u001b[39;00m nodes:\n",
      "File \u001b[1;32mD:\\Projects\\llama_index\\llama_index\\indices\\utils.py:136\u001b[0m, in \u001b[0;36membed_nodes\u001b[1;34m(nodes, embed_model, show_progress)\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    134\u001b[0m         id_to_embed_map[node\u001b[39m.\u001b[39mnode_id] \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39membedding\n\u001b[1;32m--> 136\u001b[0m new_embeddings \u001b[39m=\u001b[39m embed_model\u001b[39m.\u001b[39;49mget_text_embedding_batch(\n\u001b[0;32m    137\u001b[0m     texts_to_embed, show_progress\u001b[39m=\u001b[39;49mshow_progress\n\u001b[0;32m    138\u001b[0m )\n\u001b[0;32m    140\u001b[0m \u001b[39mfor\u001b[39;00m new_id, text_embedding \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(ids_to_embed, new_embeddings):\n\u001b[0;32m    141\u001b[0m     id_to_embed_map[new_id] \u001b[39m=\u001b[39m text_embedding\n",
      "File \u001b[1;32mD:\\Projects\\llama_index\\llama_index\\embeddings\\base.py:231\u001b[0m, in \u001b[0;36mBaseEmbedding.get_text_embedding_batch\u001b[1;34m(self, texts, show_progress)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[39mif\u001b[39;00m idx \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(texts) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(cur_batch) \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_batch_size:\n\u001b[0;32m    226\u001b[0m     \u001b[39m# flush\u001b[39;00m\n\u001b[0;32m    227\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mevent(\n\u001b[0;32m    228\u001b[0m         CBEventType\u001b[39m.\u001b[39mEMBEDDING,\n\u001b[0;32m    229\u001b[0m         payload\u001b[39m=\u001b[39m{EventPayload\u001b[39m.\u001b[39mSERIALIZED: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_dict()},\n\u001b[0;32m    230\u001b[0m     ) \u001b[39mas\u001b[39;00m event:\n\u001b[1;32m--> 231\u001b[0m         embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_text_embeddings(cur_batch)\n\u001b[0;32m    232\u001b[0m         result_embeddings\u001b[39m.\u001b[39mextend(embeddings)\n\u001b[0;32m    233\u001b[0m         event\u001b[39m.\u001b[39mon_end(\n\u001b[0;32m    234\u001b[0m             payload\u001b[39m=\u001b[39m{\n\u001b[0;32m    235\u001b[0m                 EventPayload\u001b[39m.\u001b[39mCHUNKS: cur_batch,\n\u001b[0;32m    236\u001b[0m                 EventPayload\u001b[39m.\u001b[39mEMBEDDINGS: embeddings,\n\u001b[0;32m    237\u001b[0m             },\n\u001b[0;32m    238\u001b[0m         )\n",
      "File \u001b[1;32mD:\\Projects\\llama_index\\llama_index\\embeddings\\openai.py:361\u001b[0m, in \u001b[0;36mOpenAIEmbedding._get_text_embeddings\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_text_embeddings\u001b[39m(\u001b[39mself\u001b[39m, texts: List[\u001b[39mstr\u001b[39m]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[List[\u001b[39mfloat\u001b[39m]]:\n\u001b[0;32m    355\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get text embeddings.\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \n\u001b[0;32m    357\u001b[0m \u001b[39m    By default, this is a wrapper around _get_text_embedding.\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \u001b[39m    Can be overriden for batch queries.\u001b[39;00m\n\u001b[0;32m    359\u001b[0m \n\u001b[0;32m    360\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 361\u001b[0m     \u001b[39mreturn\u001b[39;00m get_embeddings(\n\u001b[0;32m    362\u001b[0m         texts,\n\u001b[0;32m    363\u001b[0m         engine\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_text_engine,\n\u001b[0;32m    364\u001b[0m         deployment_id\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdeployment_name,\n\u001b[0;32m    365\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_all_kwargs,\n\u001b[0;32m    366\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Mussa\\.conda\\envs\\ml_env_38\\lib\\site-packages\\tenacity\\__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[1;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[1;32mc:\\Users\\Mussa\\.conda\\envs\\ml_env_38\\lib\\site-packages\\tenacity\\__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[0;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Mussa\\.conda\\envs\\ml_env_38\\lib\\site-packages\\tenacity\\__init__.py:326\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreraise:\n\u001b[0;32m    325\u001b[0m         \u001b[39mraise\u001b[39;00m retry_exc\u001b[39m.\u001b[39mreraise()\n\u001b[1;32m--> 326\u001b[0m     \u001b[39mraise\u001b[39;00m retry_exc \u001b[39mfrom\u001b[39;00m \u001b[39mfut\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexception\u001b[39;00m()\n\u001b[0;32m    328\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait:\n\u001b[0;32m    329\u001b[0m     sleep \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait(retry_state)\n",
      "\u001b[1;31mRetryError\u001b[0m: RetryError[<Future at 0x21e96350fd0 state=finished raised RateLimitError>]"
     ]
    }
   ],
   "source": [
    "documents = SimpleDirectoryReader('data').load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
